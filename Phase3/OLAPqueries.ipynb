{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PHASE 3 OLAP queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run ETL process if needed\n",
    "%run ../Phase2/ETLprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install and import here\n",
    "#%pip install psycopg2-binary\n",
    "#%pip install SQLAlchemy\n",
    "\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import sqlalchemy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from database\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../settings.ini')\n",
    "db_config = config['DB CONFIGURATION']\n",
    "try:\n",
    "    conn_string = \"postgresql://\"+db_config['USER']+\":\"+db_config['PASSWORD']+\"@\"+db_config['HOST']+\"/\"+db_config['DB_NAME']\n",
    "    conn_string = conn_string.replace(\"'\",\"\") \n",
    "    db = sqlalchemy.create_engine(conn_string, pool_pre_ping=True)\n",
    "    conn2 = db.connect()\n",
    "    fact_table_df = pd.read_sql(sql='Fact_Table',con=conn2)\n",
    "    cinfo_df = pd.read_sql(sql='ContextInfo_Dimension',con=conn2)\n",
    "    pkd_entry_df = pd.read_sql(sql='PokedexEntry_Dimension',con=conn2)\n",
    "    conn2.close()\n",
    "except Exception as e:\n",
    "    print(\"\\nError:\",e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rollup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roll up by ContextInfoKey\n",
    "rollup_df = fact_table_df.groupby('ContextInfoKey').size().reset_index(name='count')\n",
    "print(rollup_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drill down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_fin = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left')\n",
    "drill_down_df = pd.DataFrame()\n",
    "\n",
    "# Drill down by generation\n",
    "for generation, gen_group in df_fin.groupby('generation'):\n",
    "    gen_count = len(gen_group)\n",
    "    gen_group['generation_count'] = gen_count\n",
    "    drill_down_df = pd.concat([drill_down_df, gen_group[['generation', 'generation_count']]])\n",
    "drill_down_df.drop_duplicates(subset=['generation'], inplace= True)\n",
    "print(drill_down_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the water type pokemon\n",
    "slice_df = df_fin.loc[df_fin['type1'] == 'water'].reset_index()\n",
    "print(slice_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice the pokemon have both water and poison type\n",
    "dice_df = df_fin.loc[(df_fin['type1'] == 'water') & (df_fin['type2'] == 'poison')].reset_index()\n",
    "print(dice_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining OLAP operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_fin = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left')\n",
    "print(df_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1:\n",
    "# Query the fire pokemons in generation i Total attribute\n",
    "generation1_df = df_fin.loc[df_fin['generation'] == 'generation-i']\n",
    "cqueries_df_1 = generation1_df.loc[df_fin['type1'] == 'fire']\n",
    "cqueries_df_1 = cqueries_df_1[['generation', 'name', 'type1', 'TOTAL']].reset_index()\n",
    "print(cqueries_df_1)\n",
    "\n",
    "# Query 2:\n",
    "# Query the water pokemons that have variants\n",
    "cqueries_df_2 = df_fin.loc[(df_fin['type1'] == 'water') & (df_fin['is_there_variant'] == True)]\n",
    "cqueries_df_2 = cqueries_df_2[['generation', 'name', 'type1', 'is_there_variant']].reset_index()\n",
    "print(cqueries_df_2)\n",
    "\n",
    "# Query 3:\n",
    "# Query the total number of grass pokemons in each generation\n",
    "cqueries_df_3 = pd.DataFrame()\n",
    "for generation, gen_group in df_fin.groupby('generation'):\n",
    "    grass_df = gen_group.loc[df_fin['type1'] == 'grass'].copy()\n",
    "    grass_count = len(grass_df)\n",
    "    grass_df['count_grass'] = grass_count\n",
    "    cqueries_df_3 = pd.concat([cqueries_df_3,grass_df[['generation','count_grass']]])\n",
    "    cqueries_df_3.drop_duplicates(subset=['generation'], inplace= True)\n",
    "print(cqueries_df_3) \n",
    "\n",
    "\n",
    "# Query 4:\n",
    "# Query the slice of every legendary rank pokemon in generation in each generation\n",
    "cqueries_df_4 = pd.DataFrame()\n",
    "for generation, gen_group in df_fin.groupby('generation'):\n",
    "    legendary = gen_group.loc[df_fin['rank'] == 'legendary'].copy()\n",
    "    cqueries_df_4 = pd.concat([cqueries_df_4,legendary])\n",
    "print(cqueries_df_4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
