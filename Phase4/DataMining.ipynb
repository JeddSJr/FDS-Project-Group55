{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 4 Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install and imports here\n",
    "#%pip install scikit-learn \n",
    "#%pip install matplotlib\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import sqlalchemy \n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from database\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../settings.ini')\n",
    "db_config = config['DB CONFIGURATION']\n",
    "try:\n",
    "    conn_string = \"postgresql://\"+db_config['USER']+\":\"+db_config['PASSWORD']+\"@\"+db_config['HOST']+\"/\"+db_config['DB_NAME']\n",
    "    conn_string = conn_string.replace(\"'\",\"\") \n",
    "    db = sqlalchemy.create_engine(conn_string, pool_pre_ping=True)\n",
    "    conn2 = db.connect()\n",
    "    fact_table_df = pd.read_sql(sql='Fact_Table',con=conn2)\n",
    "    cinfo_df = pd.read_sql(sql='ContextInfo_Dimension',con=conn2)\n",
    "    pkd_entry_df = pd.read_sql(sql='PokedexEntry_Dimension',con=conn2)\n",
    "    conn2.close()\n",
    "except Exception as e:\n",
    "    print(\"\\nError:\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general graphs showing off total stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#seperate the pokemons by generation\n",
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "plt.hist(df_tmp['TOTAL'], bins=50)\n",
    "plt.show()\n",
    "plt.boxplot(df_tmp['TOTAL'], patch_artist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generation specific stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    " \n",
    "plt.scatter(df_tmp['generation'], df_tmp['TOTAL'])\n",
    "plt.xlabel('Generation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Total stats')\n",
    "plt.show()\n",
    "\n",
    "df_tmp2 = df_tmp.groupby('generation')['TOTAL'].mean()\n",
    "df_tmp2 = df_tmp2.reset_index()\n",
    "\n",
    "df_tmp3 = df_tmp['generation'].value_counts()\n",
    "\n",
    "type_avg = pd.merge(df_tmp2, df_tmp3, on='generation', how='left')\n",
    "type_avg.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "print(\"average total stats for each generation\")\n",
    "print(type_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_tmp = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left') \n",
    "df_tmp.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "#plot the data in order that was previously sorted\n",
    "\n",
    "fig  = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "ax.scatter(df_tmp['type1'], df_tmp['TOTAL'], color='r')\n",
    "\n",
    "#remove all None values from type2\n",
    "df_tmp = df_tmp.fillna('None')\n",
    "\n",
    "\n",
    "ax.scatter(df_tmp['type2'], df_tmp['TOTAL'], color='b')\n",
    "plt.legend(loc = 'upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#calculate the average of the total stats for each type\n",
    "df_tmp2 = df_tmp.groupby('type1')['TOTAL'].mean(df_tmp.groupby('type2')['TOTAL'])\n",
    "df_tmp2 = df_tmp2.reset_index()\n",
    "\n",
    "a = df_tmp['type1'].value_counts() \n",
    "b = df_tmp['type2'].value_counts()\n",
    "\n",
    "c = pd.Series(a + b)\n",
    "#name the columns of the series\n",
    "c = c.reset_index()\n",
    "c.columns = ['type1', 'amount']\n",
    "\n",
    "type_avg = pd.merge(df_tmp2, c, on='type1', how='left')\n",
    "\n",
    "\n",
    "type_avg.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "print(\"average total stats for each type\")\n",
    "print(type_avg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_tmp = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left') \n",
    "\n",
    "plt.scatter(df_tmp['rank'], df_tmp['TOTAL'])\n",
    "plt.show()\n",
    "\n",
    "df_tmp2 = df_tmp.groupby('rank')['TOTAL'].mean()\n",
    "df_tmp2 = df_tmp2.reset_index()\n",
    "\n",
    "df_tmp3 = df_tmp['rank'].value_counts()\n",
    "\n",
    "type_avg = pd.merge(df_tmp2, df_tmp3, on='rank', how='left')\n",
    "type_avg.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "print(\"average total stats for each rank\")\n",
    "print(type_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual stat comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_tmp = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left') \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=6, ncols=1, sharex=True, sharey=True)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "ax[0].scatter(df_tmp['HP'], df_tmp['generation'])\n",
    "ax[0].set_title('HP per Generation')\n",
    "ax[1].scatter(df_tmp['ATK'], df_tmp['generation'])\n",
    "ax[1].set_title('ATK per Generation')\n",
    "ax[2].scatter(df_tmp['DEF'], df_tmp['generation'])\n",
    "ax[2].set_title('DEF per Generation')\n",
    "ax[3].scatter(df_tmp['SPATK'], df_tmp['generation'])\n",
    "ax[3].set_title('SPATK per Generation')\n",
    "ax[4].scatter(df_tmp['SPDEF'], df_tmp['generation'])\n",
    "ax[4].set_title('SPDEF per Generation')\n",
    "ax[5].scatter(df_tmp['SPEED'], df_tmp['generation'])\n",
    "ax[5].set_title('SPEED per Generation')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode the generation column\n",
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "ohc = pd.get_dummies(df_tmp, columns= ['generation'])\n",
    "print(ohc)\n",
    "\n",
    "#ordinally encode the generation column\n",
    "le = LabelEncoder()\n",
    "df_tmp['generation'] = le.fit_transform(df_tmp['generation'])\n",
    "print(\"ordinally encoded values\")\n",
    "print(df_tmp['generation'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will be making a classifier that predicts the competitive tier of a given pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install and imports here\n",
    "%pip install requests\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json \n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download competitive pokemon data from https://smogonapi.herokuapp.com and save it to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download competitive pokemon data\n",
    "generations = [\"rb\",\"gs\",\"rs\",\"dp\",\"bw\",\"xy\",\"sm\",\"ss\",\"sv\"]\n",
    "smogonapi_getPokemonByGen_url = \"https://smogonapi.herokuapp.com/GetPokemonByGen/\"\n",
    "rqst = smogonapi_getPokemonByGen_url+generations[-1]\n",
    "response = requests.get(rqst)\n",
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save response to csv file\n",
    "print(len(response_json))\n",
    "print(response_json)\n",
    "\n",
    "csv_file = open('..\\data\\extended datasets\\competitive_df_pokemon.csv', 'w',newline='')\n",
    "writer = csv.writer(csv_file)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for data in response_json:\n",
    "    if count == 0:\n",
    "        header = data.keys()\n",
    "        writer.writerow(header)\n",
    "        count += 1\n",
    "    writer.writerow(data.values())\n",
    "    \n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the competitive data into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name         tiers dex_number\n",
      "index                                      \n",
      "0        Bulbasaur            LC          1\n",
      "9         Caterpie  National Dex         10\n",
      "99         Voltorb            LC        100\n",
      "999      Gholdengo            OU       1000\n",
      "1000      Wo-Chien            PU       1001\n",
      "...            ...           ...        ...\n",
      "994    Iron Thorns            NU        995\n",
      "995       Frigibax            LC        996\n",
      "996       Arctibax           NFE        997\n",
      "997     Baxcalibur          Uber        998\n",
      "998     Gimmighoul            LC        999\n",
      "\n",
      "[1025 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "cptv_pokemon_df = pd.read_csv(\"../data/extended datasets/competitive_df_pokemon.csv\")\n",
    "\n",
    "\n",
    "columns_to_drop = ['hp','atk','def','spa','spd','spe','weight','height','types','abilities']\n",
    "cptv_pokemon_df = cptv_pokemon_df.drop(columns_to_drop,axis=1)\n",
    "\n",
    "\n",
    "cptv_pokemon_df.query('isNonstandard != \"CAP\"',inplace=True)\n",
    "df_tmp4 = cptv_pokemon_df.copy()\n",
    "\n",
    "### Explode the dictionary to retrieve the podex id\n",
    "df_tmp4[\"oob\"] = df_tmp4[\"oob\"].astype('str')\n",
    "df_tmp4 = df_tmp4.query('oob != \"nan\"')\n",
    "\n",
    "df_tmp4.oob = df_tmp4.oob.apply(eval)\n",
    "\n",
    "tmp_col = df_tmp4.oob.apply(pd.Series)\n",
    "cptv_pokemon_df = pd.concat([\n",
    "        cptv_pokemon_df.drop('oob',axis=1),\n",
    "        tmp_col        \n",
    "        ],\n",
    "        axis=1)\n",
    "\n",
    "cptv_pokemon_df['index'] = cptv_pokemon_df['dex_number'].astype('Int64') - 1\n",
    "cptv_pokemon_df[\"dex_number\"] = cptv_pokemon_df[\"dex_number\"].astype('Int64').astype('str')\n",
    "cptv_pokemon_df = cptv_pokemon_df.query('dex_number != \"<NA>\"') \n",
    "\n",
    "### \n",
    "columns_to_drop = [\"isNonstandard\",\"evos\",\"alts\",\"genfamily\"]\n",
    "cptv_pokemon_df = cptv_pokemon_df.drop(columns_to_drop,axis=1)\n",
    "cptv_pokemon_df.formats = cptv_pokemon_df.formats.apply(lambda x: x[1:-1].split(',')[0].replace(\"'\",\"\"))\n",
    "cptv_pokemon_df.drop_duplicates(subset=['dex_number'],inplace=True)\n",
    "\n",
    "cptv_pokemon_df.set_index('index',inplace=True)\n",
    "cptv_pokemon_df.rename(columns={'formats':'tiers'},inplace=True)\n",
    "\n",
    "#print(cptv_pokemon_df.formats.apply(type))\n",
    "print(cptv_pokemon_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the competitive data frame to our fact table data frame and train our classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index DexEntryKey ContextInfoKey   HP  ATK  DEF  SPATK  SPDEF  SPEED  \\\n",
      "0         0         1-i     ordinary-i   45   49   49     65     65     45   \n",
      "1         1         2-i     ordinary-i   60   62   63     80     80     60   \n",
      "2         2         3-i     ordinary-i   80   82   83    100    100     80   \n",
      "3         3         4-i     ordinary-i   39   52   43     60     50     65   \n",
      "4         4         5-i     ordinary-i   58   64   58     80     65     80   \n",
      "...     ...         ...            ...  ...  ...  ...    ...    ...    ...   \n",
      "1020   1020     1021-ix    ordinary-ix  125   73   91    137     89     75   \n",
      "1021   1021     1022-ix    ordinary-ix   90  120   80     68    108    124   \n",
      "1022   1022     1023-ix    ordinary-ix   90   72  100    122    108     98   \n",
      "1023   1023     1024-ix   legendary-ix   90   65   85     65     85     60   \n",
      "1024   1024     1025-ix    mythical-ix   88   88  160     88     88     88   \n",
      "\n",
      "      TOTAL          name tiers dex_number  \n",
      "0       318     Bulbasaur    LC          1  \n",
      "1       405       Ivysaur   NFE          2  \n",
      "2       525      Venusaur    NU          3  \n",
      "3       309    Charmander    LC          4  \n",
      "4       405    Charmeleon   NFE          5  \n",
      "...     ...           ...   ...        ...  \n",
      "1020    590   Raging Bolt    OU       1021  \n",
      "1021    590  Iron Boulder    UU       1022  \n",
      "1022    590    Iron Crown    UU       1023  \n",
      "1023    450     Terapagos  Uber       1024  \n",
      "1024    600     Pecharunt    UU       1025  \n",
      "\n",
      "[1025 rows x 13 columns]\n",
      "       HP  ATK  DEF  SPATK  SPDEF  SPEED  TOTAL\n",
      "0      45   49   49     65     65     45    318\n",
      "1      60   62   63     80     80     60    405\n",
      "2      80   82   83    100    100     80    525\n",
      "3      39   52   43     60     50     65    309\n",
      "4      58   64   58     80     65     80    405\n",
      "...   ...  ...  ...    ...    ...    ...    ...\n",
      "1020  125   73   91    137     89     75    590\n",
      "1021   90  120   80     68    108    124    590\n",
      "1022   90   72  100    122    108     98    590\n",
      "1023   90   65   85     65     85     60    450\n",
      "1024   88   88  160     88     88     88    600\n",
      "\n",
      "[1025 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "## join our data frames and do preliminary steps for training\n",
    "\n",
    "#print(fact_table_df)\n",
    "#print(cptv_pokemon_df)\n",
    "dmm_df = fact_table_df.join(cptv_pokemon_df,on='index')#data mining df for our model\n",
    "\n",
    "\n",
    "feature_cols = ['HP','ATK','DEF', 'SPATK' , 'SPDEF'  , 'SPEED', 'TOTAL']\n",
    "features = dmm_df[feature_cols]\n",
    "target = dmm_df.tiers\n",
    "print(dmm_df)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
