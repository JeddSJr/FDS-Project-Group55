{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 4 Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install and imports here\n",
    "#%pip install scikit-learn \n",
    "#%pip install matplotlib\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import sqlalchemy \n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from database\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../settings.ini')\n",
    "db_config = config['DB CONFIGURATION']\n",
    "try:\n",
    "    conn_string = \"postgresql://\"+db_config['USER']+\":\"+db_config['PASSWORD']+\"@\"+db_config['HOST']+\"/\"+db_config['DB_NAME']\n",
    "    conn_string = conn_string.replace(\"'\",\"\") \n",
    "    db = sqlalchemy.create_engine(conn_string, pool_pre_ping=True)\n",
    "    conn2 = db.connect()\n",
    "    fact_table_df = pd.read_sql(sql='Fact_Table',con=conn2)\n",
    "    cinfo_df = pd.read_sql(sql='ContextInfo_Dimension',con=conn2)\n",
    "    pkd_entry_df = pd.read_sql(sql='PokedexEntry_Dimension',con=conn2)\n",
    "    conn2.close()\n",
    "except Exception as e:\n",
    "    print(\"\\nError:\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some general graphs showing off total stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#seperate the pokemons by generation\n",
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "plt.hist(df_tmp['TOTAL'], bins=50)\n",
    "plt.show()\n",
    "plt.boxplot(df_tmp['TOTAL'], patch_artist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generation specific stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    " \n",
    "plt.scatter(df_tmp['generation'], df_tmp['TOTAL'])\n",
    "plt.xlabel('Generation')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Total stats')\n",
    "plt.show()\n",
    "\n",
    "df_tmp2 = df_tmp.groupby('generation')['TOTAL'].mean()\n",
    "df_tmp2 = df_tmp2.reset_index()\n",
    "\n",
    "df_tmp3 = df_tmp['generation'].value_counts()\n",
    "\n",
    "type_avg = pd.merge(df_tmp2, df_tmp3, on='generation', how='left')\n",
    "type_avg.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "print(\"average total stats for each generation\")\n",
    "print(type_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_tmp = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left') \n",
    "df_tmp.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "#plot the data in order that was previously sorted\n",
    "\n",
    "fig  = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "ax.scatter(df_tmp['type1'], df_tmp['TOTAL'], color='r')\n",
    "\n",
    "#remove all None values from type2\n",
    "df_tmp = df_tmp.fillna('None')\n",
    "\n",
    "\n",
    "ax.scatter(df_tmp['type2'], df_tmp['TOTAL'], color='b')\n",
    "plt.legend(loc = 'upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#calculate the average of the total stats for each type\n",
    "df_tmp2 = df_tmp.groupby('type1')['TOTAL'].mean(df_tmp.groupby('type2')['TOTAL'])\n",
    "df_tmp2 = df_tmp2.reset_index()\n",
    "\n",
    "a = df_tmp['type1'].value_counts() \n",
    "b = df_tmp['type2'].value_counts()\n",
    "\n",
    "c = pd.Series(a + b)\n",
    "#name the columns of the series\n",
    "c = c.reset_index()\n",
    "c.columns = ['type1', 'amount']\n",
    "\n",
    "type_avg = pd.merge(df_tmp2, c, on='type1', how='left')\n",
    "\n",
    "\n",
    "type_avg.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "print(\"average total stats for each type\")\n",
    "print(type_avg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_tmp = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left') \n",
    "\n",
    "plt.scatter(df_tmp['rank'], df_tmp['TOTAL'])\n",
    "plt.show()\n",
    "\n",
    "df_tmp2 = df_tmp.groupby('rank')['TOTAL'].mean()\n",
    "df_tmp2 = df_tmp2.reset_index()\n",
    "\n",
    "df_tmp3 = df_tmp['rank'].value_counts()\n",
    "\n",
    "type_avg = pd.merge(df_tmp2, df_tmp3, on='rank', how='left')\n",
    "type_avg.sort_values(by='TOTAL', ascending=True, inplace=True)\n",
    "print(\"average total stats for each rank\")\n",
    "print(type_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual stat comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_tmp = pd.merge(fact_table_df, cinfo_df, on='ContextInfoKey', how='left')\n",
    "df_tmp = pd.merge(df_tmp, pkd_entry_df, on='DexEntryKey', how='left') \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=6, ncols=1, sharex=True, sharey=True)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "ax[0].scatter(df_tmp['HP'], df_tmp['generation'])\n",
    "ax[0].set_title('HP per Generation')\n",
    "ax[1].scatter(df_tmp['ATK'], df_tmp['generation'])\n",
    "ax[1].set_title('ATK per Generation')\n",
    "ax[2].scatter(df_tmp['DEF'], df_tmp['generation'])\n",
    "ax[2].set_title('DEF per Generation')\n",
    "ax[3].scatter(df_tmp['SPATK'], df_tmp['generation'])\n",
    "ax[3].set_title('SPATK per Generation')\n",
    "ax[4].scatter(df_tmp['SPDEF'], df_tmp['generation'])\n",
    "ax[4].set_title('SPDEF per Generation')\n",
    "ax[5].scatter(df_tmp['SPEED'], df_tmp['generation'])\n",
    "ax[5].set_title('SPEED per Generation')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install and imports here\n",
    "%pip install requests\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json \n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download competitive pokemon data from https://smogonapi.herokuapp.com and save it to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download competitive pokemon data\n",
    "generations = [\"rb\",\"gs\",\"rs\",\"dp\",\"bw\",\"xy\",\"sm\",\"ss\",\"sv\"]\n",
    "smogonapi_getPokemonByGen_url = \"https://smogonapi.herokuapp.com/GetPokemonByGen/\"\n",
    "rqst = smogonapi_getPokemonByGen_url+generations[-1]\n",
    "response = requests.get(rqst)\n",
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save response to csv file\n",
    "print(len(response_json))\n",
    "print(response_json)\n",
    "\n",
    "csv_file = open('..\\data\\extended datasets\\competitive_df_pokemon.csv', 'w',newline='')\n",
    "writer = csv.writer(csv_file)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for data in response_json:\n",
    "    if count == 0:\n",
    "        header = data.keys()\n",
    "        writer.writerow(header)\n",
    "        count += 1\n",
    "    writer.writerow(data.values())\n",
    "    \n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the competitive data into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cptv_pokemon_df = pd.read_csv(\"../data/extended datasets/competitive_df_pokemon.csv\")\n",
    "\n",
    "\n",
    "columns_to_drop = ['hp','atk','def','spa','spd','spe','weight','height','types','abilities']\n",
    "cptv_pokemon_df = cptv_pokemon_df.drop(columns_to_drop,axis=1)\n",
    "\n",
    "\n",
    "cptv_pokemon_df = cptv_pokemon_df.query('isNonstandard != \"CAP\"')\n",
    "df_tmp4 = cptv_pokemon_df.copy()\n",
    "\n",
    "### Explode the dictionary to retrieve the podex id\n",
    "df_tmp4[\"oob\"] = df_tmp4[\"oob\"].astype('str')\n",
    "df_tmp4 = df_tmp4.query('oob != \"nan\"')\n",
    "\n",
    "df_tmp4.oob = df_tmp4.oob.apply(eval)\n",
    "\n",
    "tmp_col = df_tmp4.oob.apply(pd.Series)\n",
    "cptv_pokemon_df = pd.concat([\n",
    "        cptv_pokemon_df.drop('oob',axis=1),\n",
    "        tmp_col        \n",
    "        ],\n",
    "        axis=1)\n",
    "\n",
    "cptv_pokemon_df['index'] = cptv_pokemon_df['dex_number'].astype('Int64') - 1\n",
    "cptv_pokemon_df[\"dex_number\"] = cptv_pokemon_df[\"dex_number\"].astype('Int64').astype('str')\n",
    "cptv_pokemon_df = cptv_pokemon_df.query('dex_number != \"<NA>\"') \n",
    "\n",
    "### \n",
    "columns_to_drop = [\"isNonstandard\",\"evos\",\"alts\",\"genfamily\"]\n",
    "cptv_pokemon_df = cptv_pokemon_df.drop(columns_to_drop,axis=1)\n",
    "cptv_pokemon_df.formats = cptv_pokemon_df.formats.apply(lambda x: x[1:-1].split(',')[0].replace(\"'\",\"\"))\n",
    "cptv_pokemon_df.drop_duplicates(subset=['dex_number'],inplace=True)\n",
    "\n",
    "cptv_pokemon_df.set_index('dex_number',inplace=True)\n",
    "cptv_pokemon_df.rename(columns={'formats':'tiers'},inplace=True)\n",
    "\n",
    "#print(cptv_pokemon_df.formats.apply(type))\n",
    "print(cptv_pokemon_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the competitive data frame to our fact table data frame and train our classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fact_table_df)\n",
    "print(cptv_pokemon_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
